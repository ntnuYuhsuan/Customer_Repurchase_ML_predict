{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d1bad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "raw = pd.read_csv('post_PCA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "122b155f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Logistic_Regression_0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.94      0.65      4999\n",
      "        True       0.48      0.06      0.10      4999\n",
      "\n",
      "    accuracy                           0.50      9998\n",
      "   macro avg       0.49      0.50      0.38      9998\n",
      "weighted avg       0.49      0.50      0.38      9998\n",
      "\n",
      "Model:  Decision_Tree_0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.83      0.63      4999\n",
      "        True       0.53      0.19      0.28      4999\n",
      "\n",
      "    accuracy                           0.51      9998\n",
      "   macro avg       0.52      0.51      0.45      9998\n",
      "weighted avg       0.52      0.51      0.45      9998\n",
      "\n",
      "Model:  XGBoost_0.92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.88      0.64      4999\n",
      "        True       0.51      0.12      0.19      4999\n",
      "\n",
      "    accuracy                           0.50      9998\n",
      "   macro avg       0.50      0.50      0.42      9998\n",
      "weighted avg       0.50      0.50      0.42      9998\n",
      "\n",
      "Model:  SVM_0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.95      0.66      4999\n",
      "        True       0.49      0.04      0.08      4999\n",
      "\n",
      "    accuracy                           0.50      9998\n",
      "   macro avg       0.50      0.50      0.37      9998\n",
      "weighted avg       0.50      0.50      0.37      9998\n",
      "\n",
      "Model:  SVD+Logistic_Regression_0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.94      0.65      4999\n",
      "        True       0.49      0.05      0.09      4999\n",
      "\n",
      "    accuracy                           0.50      9998\n",
      "   macro avg       0.49      0.50      0.37      9998\n",
      "weighted avg       0.49      0.50      0.37      9998\n",
      "\n",
      "CPU times: total: 1.53 s\n",
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import Counter\n",
    "# import random\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "testset = raw\n",
    "scaler = joblib.load('Models/scaler.joblib')\n",
    "# rand = random.randint(0, 99989)\n",
    "# testset = raw[raw.index.isin(analysis[analysis['cluster'] == 0].index)]\n",
    "# testset = raw[raw['REPUR_FLG']]\n",
    "\n",
    "# testset = raw.loc[rand:rand+19]\n",
    "# print(testset.head())\n",
    "# print('Ground Truth:' , Counter(testset['Y1_repurchase']))\n",
    "# print('Ground Truth:' , Counter(testset['REPUR_FLG']))\n",
    "testset = testset.drop(['Y1_repurchase', 'REPUR_FLG'], axis=1)\n",
    "testset_scaled = scaler.transform(testset)\n",
    "y = raw['REPUR_FLG']\n",
    "\n",
    "# under sampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X, y = rus.fit_resample(testset_scaled, y)\n",
    "\n",
    "for model in ['Logistic_Regression_0.97', 'Decision_Tree_0.86', 'XGBoost_0.92', 'SVM_0.97', \"SVD+Logistic_Regression_0.98\"]:\n",
    "    logi = joblib.load(f'Models/{model}.joblib')\n",
    "\n",
    "    predictions = logi.predict(X)\n",
    "    # predictions = logi.predict(testset_scaled)\n",
    "#     pred_probabilities = logi.predict_proba(testset_scaled)\n",
    "    \n",
    "    print(\"Model: \", model)\n",
    "    print(classification_report(y, predictions))\n",
    "    # print(\"Predictions:\", Counter(predictions))\n",
    "    # print(\"Prediction Probabilities:\", pred_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f04615a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>CLIENT_INCOME</th>\n",
       "      <th>total_aum</th>\n",
       "      <th>ternure_m</th>\n",
       "      <th>recency_m</th>\n",
       "      <th>topcard</th>\n",
       "      <th>UNDERTAKE</th>\n",
       "      <th>LABEL_NUM</th>\n",
       "      <th>SIN1_POL_CNT</th>\n",
       "      <th>...</th>\n",
       "      <th>contact_PC8</th>\n",
       "      <th>contact_PC9</th>\n",
       "      <th>contact_PC10</th>\n",
       "      <th>contact_PC11</th>\n",
       "      <th>contact_PC12</th>\n",
       "      <th>contact_PC13</th>\n",
       "      <th>contact_PC14</th>\n",
       "      <th>contact_PC15</th>\n",
       "      <th>contact_PC16</th>\n",
       "      <th>Y1_repurchase</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>54.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>676944.857143</td>\n",
       "      <td>951925.142857</td>\n",
       "      <td>84.571429</td>\n",
       "      <td>87.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>13.060186</td>\n",
       "      <td>3.668576</td>\n",
       "      <td>-0.691630</td>\n",
       "      <td>-2.275668</td>\n",
       "      <td>0.591107</td>\n",
       "      <td>-0.059721</td>\n",
       "      <td>0.387014</td>\n",
       "      <td>0.302108</td>\n",
       "      <td>0.156587</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.654102</td>\n",
       "      <td>0.534368</td>\n",
       "      <td>614664.904656</td>\n",
       "      <td>572083.496674</td>\n",
       "      <td>137.390244</td>\n",
       "      <td>140.261641</td>\n",
       "      <td>0.013304</td>\n",
       "      <td>0.299335</td>\n",
       "      <td>0.687361</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027823</td>\n",
       "      <td>-0.123674</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>-0.035285</td>\n",
       "      <td>-0.019677</td>\n",
       "      <td>-0.013372</td>\n",
       "      <td>-0.009801</td>\n",
       "      <td>-0.044850</td>\n",
       "      <td>-0.017671</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               AGE    GENDER  CLIENT_INCOME      total_aum   ternure_m  \\\n",
       "cluster                                                                  \n",
       "-1       54.142857  0.285714  676944.857143  951925.142857   84.571429   \n",
       " 0       36.654102  0.534368  614664.904656  572083.496674  137.390244   \n",
       "\n",
       "          recency_m   topcard  UNDERTAKE  LABEL_NUM  SIN1_POL_CNT  ...  \\\n",
       "cluster                                                            ...   \n",
       "-1        87.285714  0.000000   0.285714   3.000000      0.285714  ...   \n",
       " 0       140.261641  0.013304   0.299335   0.687361      0.048780  ...   \n",
       "\n",
       "         contact_PC8  contact_PC9  contact_PC10  contact_PC11  contact_PC12  \\\n",
       "cluster                                                                       \n",
       "-1         13.060186     3.668576     -0.691630     -2.275668      0.591107   \n",
       " 0         -0.027823    -0.123674      0.000551     -0.035285     -0.019677   \n",
       "\n",
       "         contact_PC13  contact_PC14  contact_PC15  contact_PC16  Y1_repurchase  \n",
       "cluster                                                                         \n",
       "-1          -0.059721      0.387014      0.302108      0.156587            1.0  \n",
       " 0          -0.013372     -0.009801     -0.044850     -0.017671            1.0  \n",
       "\n",
       "[2 rows x 86 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis = pd.read_csv('output/Repurchase_Clustering.csv',index_col=0)\n",
    "analysis.groupby('cluster').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e0fdccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_filter(model, df):\n",
    "    # 如果模型具有係數屬性，例如邏輯迴歸\n",
    "    if hasattr(model, 'coef_'):\n",
    "        importance = model.coef_[0]\n",
    "        feature_importance = pd.DataFrame({'Feature': df.drop(['Y1_repurchase', 'REPUR_FLG'], axis=1).columns, 'Importance': importance})\n",
    "        feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "        print(\"Feature Importance:\")\n",
    "        print(feature_importance[:3])\n",
    "    \n",
    "    # 如果模型具有特徵重要性屬性，例如隨機森林和XGBoost\n",
    "    elif hasattr(model, 'feature_importances_'):\n",
    "        importance = model.feature_importances_\n",
    "        feature_importance = pd.DataFrame({'Feature': df.drop(['Y1_repurchase', 'REPUR_FLG'], axis=1).columns, 'Importance': importance})\n",
    "        feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "        print(\"Feature Importance:\")\n",
    "        print(feature_importance[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af2842f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "[[88  5]\n",
      " [ 1 90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.95      0.97        93\n",
      "        True       0.95      0.99      0.97        91\n",
      "\n",
      "    accuracy                           0.97       184\n",
      "   macro avg       0.97      0.97      0.97       184\n",
      "weighted avg       0.97      0.97      0.97       184\n",
      "\n",
      "Accuracy: 0.97\n",
      "Feature Importance:\n",
      "               Feature  Importance\n",
      "5            recency_m  117.749987\n",
      "50  policy_ex_RATE_PC9   13.655152\n",
      "82        contact_PC14   12.217374\n",
      "\n",
      "Model: Random Forest\n",
      "[[77 16]\n",
      " [ 4 87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.83      0.89        93\n",
      "        True       0.84      0.96      0.90        91\n",
      "\n",
      "    accuracy                           0.89       184\n",
      "   macro avg       0.90      0.89      0.89       184\n",
      "weighted avg       0.90      0.89      0.89       184\n",
      "\n",
      "Accuracy: 0.89\n",
      "Feature Importance:\n",
      "      Feature  Importance\n",
      "28  label_PC4    0.103260\n",
      "4   ternure_m    0.086395\n",
      "27  label_PC3    0.073805\n",
      "\n",
      "Model: KNN\n",
      "[[55 38]\n",
      " [21 70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.59      0.65        93\n",
      "        True       0.65      0.77      0.70        91\n",
      "\n",
      "    accuracy                           0.68       184\n",
      "   macro avg       0.69      0.68      0.68       184\n",
      "weighted avg       0.69      0.68      0.68       184\n",
      "\n",
      "Accuracy: 0.68\n",
      "\n",
      "Model: Decision Tree\n",
      "[[80 13]\n",
      " [12 79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.86      0.86        93\n",
      "        True       0.86      0.87      0.86        91\n",
      "\n",
      "    accuracy                           0.86       184\n",
      "   macro avg       0.86      0.86      0.86       184\n",
      "weighted avg       0.86      0.86      0.86       184\n",
      "\n",
      "Accuracy: 0.86\n",
      "Feature Importance:\n",
      "      Feature  Importance\n",
      "28  label_PC4    0.276025\n",
      "4   ternure_m    0.240055\n",
      "5   recency_m    0.177701\n",
      "\n",
      "Model: XGBoost\n",
      "[[85  8]\n",
      " [ 6 85]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.91      0.92        93\n",
      "        True       0.91      0.93      0.92        91\n",
      "\n",
      "    accuracy                           0.92       184\n",
      "   macro avg       0.92      0.92      0.92       184\n",
      "weighted avg       0.92      0.92      0.92       184\n",
      "\n",
      "Accuracy: 0.92\n",
      "Feature Importance:\n",
      "         Feature  Importance\n",
      "79  contact_PC11    0.111432\n",
      "28     label_PC4    0.087101\n",
      "5      recency_m    0.040768\n",
      "\n",
      "Model: SVM\n",
      "[[89  4]\n",
      " [ 1 90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.96      0.97        93\n",
      "        True       0.96      0.99      0.97        91\n",
      "\n",
      "    accuracy                           0.97       184\n",
      "   macro avg       0.97      0.97      0.97       184\n",
      "weighted avg       0.97      0.97      0.97       184\n",
      "\n",
      "Accuracy: 0.97\n",
      "Feature Importance:\n",
      "         Feature  Importance\n",
      "5      recency_m   66.301579\n",
      "82  contact_PC14   16.286694\n",
      "76   contact_PC8    4.696136\n",
      "\n",
      "Model: SVD+Logistic Regression\n",
      "[[90  3]\n",
      " [ 0 91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.97      0.98        93\n",
      "        True       0.97      1.00      0.98        91\n",
      "\n",
      "    accuracy                           0.98       184\n",
      "   macro avg       0.98      0.98      0.98       184\n",
      "weighted avg       0.98      0.98      0.98       184\n",
      "\n",
      "Accuracy: 0.98\n",
      "\n",
      "CPU times: total: 5.17 s\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random_state = 313\n",
    "df = raw\n",
    "# X = df.drop(['Y1_repurchase', 'recency_m'], axis=1)\n",
    "X = df.drop(['Y1_repurchase', 'REPUR_FLG'], axis=1)\n",
    "y = df['Y1_repurchase']\n",
    "# y = df['REPUR_FLG']\n",
    "# y = df.index.isin(analysis[analysis['cluster'] == 0].index)\n",
    "\n",
    "# 標準化特徵\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# joblib.dump(scaler, 'Models/scaler.joblib')\n",
    "# joblib.dump(scaler, 'Models/RF_scaler.joblib')\n",
    "\n",
    "rus = RandomUnderSampler(random_state=random_state)\n",
    "X_scaled, y = rus.fit_resample(X_scaled, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(C=1000, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(max_depth=80, n_estimators=300),\n",
    "    # 'Random Forest': RandomForestClassifier(max_depth=80, n_estimators=200),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    # 'KNN': KNeighborsClassifier(n_neighbors=9),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=8, min_samples_split=3),\n",
    "    # 'Decision Tree': DecisionTreeClassifier(max_depth=8, min_samples_split=2),\n",
    "    'XGBoost': XGBClassifier(learning_rate=0.15, max_depth=4, n_estimators=200),\n",
    "    # 'XGBoost': XGBClassifier(learning_rate=0.13, max_depth=3, n_estimators=150),\n",
    "    'SVM': SVC(C=500, gamma=0.1, kernel='linear', probability=True), # probability=True\n",
    "    # 'SVM': SVC(C=800, gamma=0.1, kernel='linear', probability=True),\n",
    "    'SVD+Logistic Regression': make_pipeline(TruncatedSVD(n_components=50), LogisticRegression(C=1000, max_iter=1000))\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "#     print(name, accuracy)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    \n",
    "    feature_filter(model, df)\n",
    "    \n",
    "    # joblib.dump(model, f\"Models/RF_{name.replace(' ', '_')}_{accuracy:.2f}.joblib\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e298434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrongly predicted indices: [7, 16, 21, 32, 38, 41, 43, 57, 60, 62, 76, 96, 98, 103, 113, 114, 115, 118, 119, 138, 140, 157, 158, 178]\n"
     ]
    }
   ],
   "source": [
    "wrong_indices = [i for i, (pred, true) in enumerate(zip(y_pred, y_test)) if pred != true]\n",
    "print(f\"Wrongly predicted indices: {wrong_indices}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf58ba9b",
   "metadata": {},
   "source": [
    "Best parameters for Logistic Regression: {'C': 1000}\n",
    "Best cross-validation accuracy: 0.98\n",
    "Best parameters for Random Forest: {'max_depth': 80, 'n_estimators': 300}\n",
    "Best cross-validation accuracy: 0.86\n",
    "Best parameters for Decision Tree: {'max_depth': 8, 'min_samples_split': 3}\n",
    "Best cross-validation accuracy: 0.87\n",
    "Best parameters for XGBoost: {'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 200}\n",
    "Best cross-validation accuracy: 0.93\n",
    "Best parameters for SVM: {'C': 500, 'gamma': 0.1, 'kernel': 'linear'}\n",
    "Best cross-validation accuracy: 0.99\n",
    "Best parameters for SVD + Logistic Regression: {'logisticregression__C': 1000}\n",
    "Best cross-validation accuracy: 0.98"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e490d8b",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "RF GridSearchCV\n",
    "\n",
    "Best parameters for Logistic Regression: {'C': 1000}\n",
    "Best cross-validation accuracy: 0.61\n",
    "Best parameters for Random Forest: {'max_depth': 80, 'n_estimators': 200}\n",
    "Best cross-validation accuracy: 0.61\n",
    "Best parameters for KNN: {'n_neighbors': 9}\n",
    "Best cross-validation accuracy: 0.57\n",
    "Best parameters for Decision Tree: {'max_depth': 8, 'min_samples_split': 2}\n",
    "Best cross-validation accuracy: 0.60\n",
    "Best parameters for XGBoost: {'learning_rate': 0.13, 'max_depth': 3, 'n_estimators': 150}\n",
    "Best cross-validation accuracy: 0.61\n",
    "Best parameters for SVM: {'C': 800, 'gamma': 0.1, 'kernel': 'linear'}\n",
    "Best cross-validation accuracy: 0.61\n",
    "Best parameters for SVD+Logistic Regression: {'logisticregression__C': 1000}\n",
    "Best cross-validation accuracy: 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19c31522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for SVD+Logistic Regression: {'logisticregression__C': 1000}\n",
      "Best cross-validation accuracy: 0.97\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 852 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    # 'Logistic Regression': {'C': [500, 1000]},\n",
    "    # 'Random Forest': {'n_estimators': [150, 200, 300, 450], 'max_depth': [40, 50, 60, 80]},\n",
    "    # 'KNN': {'n_neighbors': [3, 5, 7, 9]},\n",
    "    # 'Decision Tree': {'max_depth': [8, 10, 12], 'min_samples_split': [2, 3, 4]},\n",
    "    # 'XGBoost': {'learning_rate': [0.13, 0.15, 0.2, 0.5], \n",
    "    #             'n_estimators': [150, 200, 250], 'max_depth': [3, 4, 5]},\n",
    "    # 'SVM': {'C': [350, 500, 800],'kernel': ['linear', 'rbf', 'poly'],\n",
    "    #           'gamma': [0.1, 0.15, 0.08]},\n",
    "    'SVD+Logistic Regression': {'logisticregression__C': [200, 300, 500, 1000]}\n",
    "}\n",
    "\n",
    "# 使用網格搜索進行參數優化\n",
    "for name, model in models.items():\n",
    "    if name in param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid[name], cv=5, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_\n",
    "        print(f\"Best parameters for {name}: {best_params}\")\n",
    "        print(f\"Best cross-validation accuracy: {best_score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
